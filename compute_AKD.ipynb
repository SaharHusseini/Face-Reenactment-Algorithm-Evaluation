{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This script finds the facial keypoint and compute keypoint distance between ground truth and generated frames. \n",
    "we use Mediapipe to find facial keypoints.\n",
    "To run the script, install cv2, numpy, mediapipe and pandas\n",
    "\n",
    "\n",
    "maybe you will need to run following command on your envirement before running the script (if you get error)\n",
    "!export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "\n",
    "we use face_landmark env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from re import X\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change following paths to match your ground-truth path (ground_truth_parent_directory) and path where the generated frames by your algorithm  are located (generated_parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_parent_directory = '3D_real_head_dataset/images/ground_truth/'\n",
    "generated_parent_directory = 'DAGAN_results_3D_heads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Directories containing ground-truth \n",
    "ground_truth_directories = [ground_truth_parent_directory+d for d in os.listdir(ground_truth_parent_directory) \n",
    "                            if os.path.isdir(os.path.join(ground_truth_parent_directory, d))]\n",
    "#Directories containing generated reenactment frames \n",
    "generated_directories = [generated_parent_directory+d for d in os.listdir(generated_parent_directory) \n",
    "                         if os.path.isdir(os.path.join(generated_parent_directory, d))] \n",
    "\n",
    "#For each ground-truth find all deepfake folders that contain the same head rotation.\n",
    "#ground-truth folder is key and the value is gnerated folders (both contain the same head rotation)\n",
    "gt_gen_path_dict = {}\n",
    "for dir_gt in ground_truth_directories:\n",
    "    rotation_type_gt = dir_gt.split('/')[-1].split('_')[0] #head rotation of ground-truth\n",
    "    if rotation_type_gt not in gt_gen_path_dict:\n",
    "                gt_gen_path_dict[dir_gt] = []\n",
    "    #if the same head rotation is found in generated folder, add it as a value to dict\n",
    "    for dir_gen in generated_directories: \n",
    "        rotation_type_gen = dir_gen.split('/')[-1].split('_')[0]\n",
    "        \n",
    "        if rotation_type_gen == rotation_type_gt:\n",
    "            gt_gen_path_dict[dir_gt].append(dir_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(x_list_orig, y_list_orig, x_list, y_list):\n",
    "    \"\"\"\n",
    "    Compute SSIM score between video frames.\n",
    "    Args:\n",
    "    orig_frame: ground-truth frame.\n",
    "    fake_frame: fake frame\n",
    "    Returns:\n",
    "    SSIM score between ground-truth and fake frame\n",
    "    \"\"\"\n",
    "    #computes mean squared error for one frame\n",
    "    x_difference = (np.array(x_list_orig) - np.array(x_list))**2\n",
    "    y_difference = (np.array(y_list_orig) - np.array(y_list))**2\n",
    "    squared_error = np.sqrt(x_difference + y_difference)\n",
    "    MSE = squared_error.mean()\n",
    "    return MSE\n",
    "\n",
    "\n",
    "def compute_AKD(path_fake, path_gr):\n",
    "    \"\"\"\n",
    "    Compute average keypoint distance between two video frames.\n",
    "    Args:\n",
    "    path_fake: path belonging to fake video frame.\n",
    "    path_gr:path belonging to ground-truth  video frame. \n",
    "    Returns:\n",
    "    Mean Square Error between keypoints\n",
    "    \"\"\"\n",
    "    x1_list = []\n",
    "    y1_list = []\n",
    "    x2_list = []\n",
    "    y2_list = []\n",
    "    original_img =  cv2.imread(path_gr)\n",
    "    fake_img =  cv2.imread(path_fake)\n",
    "    height, width, _ = original_img.shape\n",
    "    result_original = face_mesh.process(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "    result_fake = face_mesh.process(cv2.cvtColor(fake_img, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "    if result_original.multi_face_landmarks is not None:\n",
    "        for idx, facial_landmarks in enumerate(result_original.multi_face_landmarks):\n",
    "            for i in range(0, 468): #468\n",
    "                pt1 = facial_landmarks.landmark[i]\n",
    "                x1 = int(pt1.x * width)   #scale the landmarks to fit the image size\n",
    "                y1 = int(pt1.y * height)\n",
    "                x1_list.append(x1)\n",
    "                y1_list.append(y1)\n",
    "                #saving results for later. if the landmark landmark can not be found we use the landmark of last frame\n",
    "                pr_x1_list = x1_list\n",
    "                pr_y1_list = y1_list\n",
    "                \n",
    "    if result_fake.multi_face_landmarks is not None:            \n",
    "        for idx, facial_landmarks in enumerate(result_fake.multi_face_landmarks):\n",
    "            for i in range(0, 468): #468\n",
    "                pt2 = facial_landmarks.landmark[i]\n",
    "                x2 = int(pt2.x * width)   #scale the landmarks to fit the image size\n",
    "                y2 = int(pt2.y * height)\n",
    "                x2_list.append(x2)\n",
    "                y2_list.append(y2)\n",
    "                pr_x2_list = x2_list\n",
    "                pr_y2_list = y2_list\n",
    "    #if there is occlussion or the keypoints can not be found===========\n",
    "    if result_original.multi_face_landmarks is None:\n",
    "        print(path_gr)\n",
    "        x1_list = pr_x1_list\n",
    "        y1_list = pr_y1_list \n",
    "        with open ('fileFailed.txt', 'w') as file:  \n",
    "            file.write(path_gr)  \n",
    "            file.write('\\n')  \n",
    "    \n",
    "    if result_fake.multi_face_landmarks is None:\n",
    "        print(path_fake)\n",
    "        x2_list = pr_x2_list\n",
    "        y2_list = pr_y2_list  \n",
    "        with open ('fileFailed.txt', 'w') as file:  \n",
    "            file.write(path_fake) \n",
    "            file.write('\\n')  \n",
    "    \n",
    "    #compute mean square error                    \n",
    "    mse = MSE(x1_list, y1_list, x2_list, y2_list)\n",
    "    return mse\n",
    "\n",
    "def compute_AKD_per_frame(original_path, path1, path2, path3, path4):\n",
    "    \"\"\"\n",
    "    Compute average leypoint distance between ground truth and generated frames for one video (100 frames). We use 4 different \n",
    "    identities to generate the same head rotation \n",
    "    Args:\n",
    "    original_path: path to ground-truth directory\n",
    "    path1, path2, path3, path4: path to deepfake generated directories. Inside each path we have fake frames generated\n",
    "    by different identities\n",
    "    Returns:\n",
    "    A list of AKD scores between the ground-truth frames and fake frames. The score for each frame is the average\n",
    "    over the four generated images.\n",
    "    \"\"\"\n",
    "    ssim_list = []\n",
    "    ground_truth_frames_212 = [original_path + '/' + d for d in sorted(os.listdir(original_path))]\n",
    "    generated_frames_122 = [path1 + '/' + d for d in sorted(os.listdir(path1))]\n",
    "    generated_frames_340 = [path2 + '/' + d for d in sorted(os.listdir(path2))]\n",
    "    generated_frames_344 = [path3 + '/' + d for d in sorted(os.listdir(path3))]\n",
    "    generated_frames_359 = [path4 + '/' + d for d in sorted(os.listdir(path4))]\n",
    "    print(original_path)\n",
    "    for ground_truth, gen_122, gen_340, gen_344, gen_359 in zip(ground_truth_frames_212, \n",
    "                                                            generated_frames_122, \n",
    "                                                            generated_frames_340,\n",
    "                                                            generated_frames_344,\n",
    "                                                            generated_frames_359):\n",
    "        \n",
    "        AKD_score_122 = compute_AKD(ground_truth, gen_122 )\n",
    "        AKD_score_340 = compute_AKD(ground_truth, gen_340)\n",
    "        AKD_score_344 = compute_AKD(ground_truth, gen_344)\n",
    "        AKD_score_359= compute_AKD(ground_truth, gen_359)\n",
    "        \n",
    "        mean_ssim = (AKD_score_122+AKD_score_340+AKD_score_344+AKD_score_359)/4 \n",
    "        ssim_list.append(mean_ssim)\n",
    "    return ssim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pitchNegative\n",
      "3D_real_head_dataset/images/ground_truth/pitchNegative_id212\n",
      "pitchPositive\n",
      "yawPositive\n",
      "3D_real_head_dataset/images/ground_truth/yawPositive_id212\n",
      "pitchYawNegative\n",
      "yawNegative\n",
      "pitchYawPositive\n",
      "3D_real_head_dataset/images/ground_truth/pitchYawPositive_id212\n",
      "    image_name  pitchNegative  yawPositive  pitchYawPositive\n",
      "0   00000.jpeg       0.789640     0.789640          0.789327\n",
      "1   00001.jpeg       1.075664     1.135425          0.929548\n",
      "2   00002.jpeg       0.739468     1.153049          1.062155\n",
      "3   00003.jpeg       1.121030     1.063673          1.049822\n",
      "4   00004.jpeg       1.083410     1.077800          1.155328\n",
      "..         ...            ...          ...               ...\n",
      "95  00095.jpeg       3.000428     4.558575          8.849054\n",
      "96  00096.jpeg       3.014359     4.738374          8.479550\n",
      "97  00097.jpeg       3.058185     4.727494          8.820415\n",
      "98  00098.jpeg       3.211079     4.720431          8.899235\n",
      "99  00099.jpeg       2.969148     4.758453          9.743745\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    # Create a dataframe to store image name and SSIM score for different head rotation per frame\n",
    "    dataframe = pd.DataFrame({'image_name': []})\n",
    "    for groundtruth_path, generate_path  in gt_gen_path_dict.items():\n",
    "        names = [d for d in sorted(os.listdir(groundtruth_path))] #video frame names\n",
    "        dataframe[\"image_name\"] = names \n",
    "        AKD_list = []\n",
    "        rotatio_type = groundtruth_path.split('/')[-1].split('_')[0]\n",
    "        print(rotatio_type)\n",
    "        #In the paper we only evaluate the three head rotations below\n",
    "        if rotatio_type == \"pitchNegative\": #head rotation of ground-truth\n",
    "            AKD_list = compute_AKD_per_frame(groundtruth_path, generate_path[0], generate_path[1], \n",
    "                                                generate_path[2], generate_path[3])\n",
    "            dataframe[\"pitchNegative\"] = AKD_list\n",
    "            \n",
    "            \n",
    "        if rotatio_type == \"yawPositive\": #head rotation of ground-truth\n",
    "            AKD_list = compute_AKD_per_frame(groundtruth_path, generate_path[0], generate_path[1], \n",
    "                                                generate_path[2], generate_path[3])\n",
    "            dataframe[\"yawPositive\"] = AKD_list\n",
    "            \n",
    "                    \n",
    "        if rotatio_type == \"pitchYawPositive\": #head rotation of ground-truth\n",
    "            AKD_list = compute_AKD_per_frame(groundtruth_path, generate_path[0], generate_path[1], \n",
    "                                                generate_path[2], generate_path[3])\n",
    "            dataframe[\"pitchYawPositive\"] = AKD_list\n",
    "    \n",
    "    print(dataframe)   \n",
    "    csv_path =   \"cv_scores/\"+generated_parent_directory\n",
    "    if not os.path.exists(csv_path):\n",
    "        os.makedirs(csv_path, exist_ok=True)\n",
    "                \n",
    "    dataframe.to_csv(csv_path+\"AKD_scores_per_frame.csv\")  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
